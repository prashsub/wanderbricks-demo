---
description: Comprehensive documentation standards for Gold layer tables including naming conventions, column descriptions, and metadata requirements
globs: src/**/*gold*.py
alwaysApply: false
---

# Gold Layer Documentation Standards

## Pattern Recognition
Gold layer tables require comprehensive, dual-purpose documentation that serves both business users and technical users (including LLMs like Genie). This rule standardizes naming conventions, description formats, and metadata requirements.

## Core Principles

### 0. YAML Schema Files Are the Single Source of Truth

**CRITICAL:** Before writing any Gold layer SQL (TVFs, queries, MERGE statements), ALWAYS consult the YAML schema definitions in `gold_layer_design/yaml/**/*.yaml`.

**Why This Matters:**
- YAML files define the actual DDL used to create tables
- Assumptions about "standard" naming conventions are often wrong
- 5 minutes reading YAML prevents 40+ minutes debugging column name errors

**Pre-Development Checklist:**
- [ ] Read YAML schema files for all tables referenced in your SQL
- [ ] Check actual column names (not assumptions)
- [ ] Note SCD Type 1 vs Type 2 (impacts is_current filters)
- [ ] Document findings in SCHEMA_MAPPING.md

**Common Mistakes:**
- ❌ Assuming `city` exists → Actually `destination` in dim_destination
- ❌ Assuming `state` exists → Actually `state_or_province` in dim_destination
- ❌ Forgetting `is_current = true` filter for SCD Type 2 dimensions
- ❌ Referencing columns from wrong table (fact vs dimension)

**Reference:** See `src/wanderbricks_gold/tvfs/SCHEMA_MAPPING.md` for comprehensive schema documentation.

**Impact:** TVF deployment post-mortem (2025-12-10) showed 100% of SQL compilation errors (30+ instances across 6 deployment iterations) were caused by not consulting YAML schemas first.

### 1. Dual-Purpose Documentation
Every description must serve **both business and technical audiences** without requiring an "LLM:" prefix.

**Pattern:**
```
[Natural description]. Business: [business context and use cases]. Technical: [implementation details and calculations].
```

### 2. Surrogate Keys as Primary Keys
Follow proper dimensional modeling with surrogate keys:
- **Surrogate keys** (store_key, product_key, date_key) are PRIMARY KEYS
- **Business keys** (store_number, upc_code, date) are denormalized for readability
- **Facts reference surrogate PKs** via foreign keys

### 3. Comprehensive Context
Documentation must explain:
- What the field is (definition)
- Why it exists (business purpose)
- How it's used (use cases)
- How it's calculated (technical logic)

## Column Naming Conventions

### Surrogate Keys (Dimension PKs)
```python
store_key STRING NOT NULL COMMENT 'Surrogate key uniquely identifying each version of a store record. Business: Used for joining fact tables to dimension. Technical: MD5 hash generated from store_id and processed_timestamp to ensure uniqueness across SCD Type 2 versions.'

product_key STRING NOT NULL COMMENT 'Surrogate key uniquely identifying each product. Business: Used for joining fact tables to product dimension. Technical: MD5 hash of UPC code, ensures stable identifier even if UPC format changes.'

date_key INT NOT NULL COMMENT 'Integer surrogate key for fast joins in YYYYMMDD format. Business: Used for joining fact tables to date dimension. Technical: Format 20250115 for Jan 15, 2025. Integer type enables faster joins than date comparisons.'
```

**Naming Pattern:**
- `{entity}_key` for surrogate keys
- Always `NOT NULL`
- Always commented with generation logic

### Business Keys (Natural Identifiers)
```python
store_number STRING NOT NULL COMMENT 'Business key identifying the physical store location. Business: The primary identifier used by store operations and field teams. Technical: Natural key from source system, same across all historical versions of this store.'

upc_code STRING NOT NULL COMMENT 'Universal Product Code barcode identifier. Business: Primary product identifier scanned at point of sale, used for product lookup and inventory management. Technical: 12-14 digit numeric code, validated against UPC standards.'

date DATE NOT NULL COMMENT 'Actual calendar date. Business: The natural date value used for filtering and display in reports. Technical: Standard SQL DATE type, use for human-readable date operations.'
```

**Naming Pattern:**
- Use natural business terminology
- Include in facts for human readability (denormalized)
- Document that they match surrogate keys

### Foreign Keys in Facts
```python
# Surrogate FK (joins to dimension)
store_key STRING NOT NULL COMMENT 'Surrogate foreign key to dim_store. Business: Joins to store dimension for store attributes and location analysis. Technical: References dim_store.store_key (PRIMARY KEY), enables fast hash joins.'

# Denormalized business key (readability)
store_number STRING NOT NULL COMMENT 'Store business key for human readability. Business: Natural store identifier used by operations, included for query convenience and readability. Technical: Denormalized from dim_store, matches store_key but human-friendly.'
```

**Naming Pattern:**
- Surrogate FKs: `{entity}_key`
- Business keys: Natural names (store_number, upc_code)
- Always document the relationship and purpose

### Measures and Metrics
```python
# Revenue measures
gross_revenue DECIMAL(18,2) COMMENT 'Total revenue before returns. Business: Gross sales dollars including all positive transactions before any returns are subtracted. Used to measure top-line sales performance. Technical: SUM(final_sales_price) WHERE quantity_sold > 0.'

net_revenue DECIMAL(18,2) COMMENT 'Net revenue after subtracting returns from gross revenue. Business: The actual revenue realized from sales, primary KPI for financial reporting. Technical: gross_revenue - return_amount, represents true daily sales value.'

# Count measures
transaction_count BIGINT COMMENT 'Total number of sale transactions. Business: Count of all sales events including both sales and returns. Used for traffic analysis and basket metrics. Technical: COUNT(DISTINCT transaction_id).'

# Ratio measures
return_rate_pct DECIMAL(5,2) COMMENT 'Return rate as percentage of gross sales. Business: Percentage of gross revenue lost to returns. Used to identify quality issues and customer satisfaction problems. Technical: (return_amount / gross_revenue) * 100, NULL when gross_revenue = 0.'
```

**Naming Pattern:**
- Descriptive business names (avoid abbreviations except standard ones)
- Suffix `_pct` for percentages
- Suffix `_total` for sums
- Suffix `_avg` for averages
- Document calculation formula in Technical section

### Derived Fields
```python
store_age_days INT COMMENT 'Number of days since store opened. Business: Used to analyze store maturity, compare new vs established stores, and track performance over store lifecycle. Technical: Calculated as DATEDIFF(CURRENT_DATE(), open_date).'

days_of_supply DECIMAL(10,1) COMMENT 'Estimated days until stockout at forecasted demand rate. Business: How many days the current inventory will last. Critical metric for replenishment timing and stock planning. Technical: Calculated as current_on_hand / (current_forecast / forecast_period_days), NULL when forecast is 0.'
```

**Naming Pattern:**
- Clear, self-documenting names
- Include unit (days, hours, pct)
- Always document calculation logic

### Boolean Flags
```python
is_current BOOLEAN NOT NULL COMMENT 'Flag indicating if this is the current active version. Business: TRUE for current store attributes, FALSE for historical records. Used with WHERE is_current = true to get latest state. Technical: SCD Type 2 flag, updated to FALSE when new version created.'

needs_replenishment BOOLEAN COMMENT 'Flag indicating urgent replenishment required. Business: TRUE when inventory is below minimum threshold and requires immediate reorder. Used to generate replenishment orders and alerts. Technical: TRUE when current_on_hand < current_minimum OR days_of_supply < reorder_threshold.'
```

**Naming Pattern:**
- Prefix with `is_` for state flags (is_current, is_weekend, is_premium)
- Prefix with verb for action flags (needs_replenishment, requires_attention)
- Document TRUE/FALSE meanings and business rules

### Timestamp Fields
```python
effective_from TIMESTAMP NOT NULL COMMENT 'Start timestamp for this version of the store record. Business: Indicates when this set of store attributes became active. Technical: SCD Type 2 field, populated from processed_timestamp when new version created.'

effective_to TIMESTAMP COMMENT 'End timestamp for this version of the store record. Business: NULL indicates this is the current version. Non-NULL indicates historical record. Technical: SCD Type 2 field, set to next version effective_from when superseded.'

record_created_timestamp TIMESTAMP COMMENT 'Timestamp when this record was first inserted into the Gold layer. Business: Audit field for data lineage and troubleshooting. Technical: Set once at INSERT time, never updated.'

record_updated_timestamp TIMESTAMP COMMENT 'Timestamp when this record was last modified. Business: Audit field showing data freshness and update history. Technical: Updated on every MERGE operation that modifies the record.'
```

**Naming Pattern:**
- `effective_from` / `effective_to` for SCD Type 2
- `record_created_timestamp` / `record_updated_timestamp` for audit
- Always document update behavior

## Column Description Format

### Standard Template
Every column description must follow this structure:

```
[One-sentence definition]. Business: [Business purpose, use cases, and context]. Technical: [Data type, format, calculation logic, source, constraints].
```

### Required Elements

1. **Opening Sentence:** Clear, natural language definition
2. **Business Section:** 
   - What business problem it solves
   - How business users will use it
   - Key use cases and decisions it supports
   - Business rules and expected values
3. **Technical Section:**
   - Data type and format specifics
   - Calculation or derivation logic
   - Source system or table
   - Constraints, validations, or special handling
   - Performance implications (for keys)

### Examples by Field Type

#### Surrogate Key
```python
product_key STRING NOT NULL COMMENT 'Surrogate key uniquely identifying each product. Business: Used for joining fact tables to product dimension. Technical: MD5 hash of UPC code, ensures stable identifier even if UPC format changes.'
```

#### Business Key
```python
upc_code STRING NOT NULL COMMENT 'Universal Product Code barcode identifier. Business: Primary product identifier scanned at point of sale, used for product lookup and inventory management. Technical: 12-14 digit numeric code, validated against UPC standards.'
```

#### Foreign Key
```python
store_key STRING NOT NULL COMMENT 'Surrogate foreign key to dim_store. Business: Joins to store dimension for store attributes and location analysis. Technical: References dim_store.store_key (PRIMARY KEY), enables fast hash joins.'
```

#### Measure
```python
net_revenue DECIMAL(18,2) COMMENT 'Net revenue after subtracting returns from gross revenue. Business: The actual revenue realized from sales, primary KPI for financial reporting. Technical: gross_revenue - return_amount, represents true daily sales value.'
```

#### Calculated Field
```python
return_rate_pct DECIMAL(5,2) COMMENT 'Return rate as percentage of gross sales. Business: Percentage of gross revenue lost to returns. Used to identify quality issues and customer satisfaction problems. Technical: (return_amount / gross_revenue) * 100, NULL when gross_revenue = 0.'
```

#### Boolean Flag
```python
is_current BOOLEAN NOT NULL COMMENT 'Flag indicating if this is the current active version. Business: TRUE for current store attributes, FALSE for historical records. Used with WHERE is_current = true to get latest state. Technical: SCD Type 2 flag, updated to FALSE when new version created.'
```

#### Date/Time
```python
transaction_date DATE NOT NULL COMMENT 'Transaction calendar date for human readability. Business: Natural date value for filtering and display, included for query convenience. Technical: Denormalized from dim_date, matches date_key but human-friendly.'
```

## Table-Level Documentation

### Table Comment Format

Every Gold table must have a comprehensive comment covering:
1. Layer and purpose
2. Grain (what one row represents)
3. Business use cases
4. Technical implementation

```python
COMMENT 'Gold layer daily sales fact table with pre-aggregated metrics at store-product-day grain. Business: Primary source for sales performance reporting including revenue, units, discounts, returns, and customer loyalty metrics. Aggregated from transaction-level Silver data for fast query performance. Used for dashboards, executive reporting, and sales analysis. Technical: Grain is one row per store-product-date combination. Pre-aggregated measures eliminate need for transaction-level scans, surrogate keys enable fast dimension joins.'
```

### Dimension Table Comment Pattern
```python
COMMENT 'Gold layer conformed {entity} dimension with {SCD Type}. Business: {Business purpose, history tracking, use cases}. Technical: {SCD implementation details, key strategy, update behavior}.'
```

**Example:**
```python
COMMENT 'Gold layer conformed store dimension with SCD Type 2 history tracking. Business: Maintains complete store lifecycle history including address changes, status updates, and operational attributes. Each store version tracked separately for point-in-time analysis. Technical: Slowly Changing Dimension Type 2 implementation with effective dating, surrogate keys enable proper fact table joins to historical store states.'
```

### Fact Table Comment Pattern
```python
COMMENT 'Gold layer {period} {subject} fact table with {aggregation level} at {grain}. Business: {Primary use cases, metrics included, reporting purpose}. Technical: Grain is {what one row represents}. {Performance optimizations, key relationships}.'
```

**Example:**
```python
COMMENT 'Gold layer daily sales fact table with pre-aggregated metrics at store-product-day grain. Business: Primary source for sales performance reporting including revenue, units, discounts, returns, and customer loyalty metrics. Aggregated from transaction-level Silver data for fast query performance. Used for dashboards, executive reporting, and sales analysis. Technical: Grain is one row per store-product-date combination. Pre-aggregated measures eliminate need for transaction-level scans, surrogate keys enable fast dimension joins.'
```

## Table Properties

### Required Properties for Gold Layer
```python
TBLPROPERTIES (
    # Performance
    'delta.enableChangeDataFeed' = 'true',
    'delta.enableRowTracking' = 'true',
    'delta.enableDeletionVectors' = 'true',
    'delta.autoOptimize.autoCompact' = 'true',
    'delta.autoOptimize.optimizeWrite' = 'true',
    
    # Layer and Quality
    'quality' = 'gold',
    'layer' = 'gold',
    'source_layer' = 'silver',
    'source_table' = '<silver_source_table>',
    
    # Domain and Classification
    'domain' = '<retail|sales|inventory|product>',
    'entity_type' = '<dimension|fact>',
    
    # Governance
    'contains_pii' = '<true|false>',
    'data_classification' = '<confidential|internal|public>',
    'business_owner' = '<Team Name>',
    'technical_owner' = 'Data Engineering',
    
    # Dimension-specific (if applicable)
    'scd_type' = '<1|2>',
    
    # Fact-specific (if applicable)
    'grain' = '<description of grain>',
    'gold_type' = '<aggregated|snapshot>'
)
```

### Property Guidelines

**Entity Type:**
- `dimension` for lookup tables
- `fact` for measurement tables

**SCD Type (dimensions only):**
- `1` for overwrite (no history)
- `2` for versioned history

**Grain (facts only):**
Examples:
- `daily_store_product` - one row per store-product-day
- `store_product_snapshot` - one row per store-product (current state)
- `transaction_level` - one row per transaction

**Data Classification:**
- `confidential` - Contains PII or sensitive business data
- `internal` - Business data without PII
- `public` - Safe for external sharing (rare)

## Complete Table Example

### Dimension Table (SCD Type 2)
```python
def create_dim_store(spark: SparkSession, catalog: str, schema: str):
    """Create dim_store table (SCD Type 2)."""
    table_name = f"{catalog}.{schema}.dim_store"
    
    spark.sql(f"""
        CREATE OR REPLACE TABLE {table_name} (
            -- Surrogate key (PRIMARY KEY)
            store_key STRING NOT NULL 
                COMMENT 'Surrogate key uniquely identifying each version of a store record. Business: Used for joining fact tables to dimension. Technical: MD5 hash generated from store_id and processed_timestamp to ensure uniqueness across SCD Type 2 versions.',
            
            -- Business key (natural identifier)
            store_number STRING NOT NULL 
                COMMENT 'Business key identifying the physical store location. Business: The primary identifier used by store operations and field teams. Technical: Natural key from source system, same across all historical versions of this store.',
            
            -- Attributes
            store_name STRING 
                COMMENT 'Official name of the retail store location. Business: Used for customer-facing communications and internal reporting. Technical: Free-text field from POS system, may change over time.',
            
            city STRING 
                COMMENT 'City name where the store is located. Business: Used for geographic analysis and territory management. Technical: Standardized city name from address validation.',
            
            state STRING 
                COMMENT 'Two-letter US state code. Business: Used for state-level sales analysis and compliance reporting. Technical: Validated against standard US state abbreviations (CA, TX, NY, etc.).',
            
            -- SCD Type 2 fields
            effective_from TIMESTAMP NOT NULL 
                COMMENT 'Start timestamp for this version of the store record. Business: Indicates when this set of store attributes became active. Technical: SCD Type 2 field, populated from processed_timestamp when new version created.',
            
            effective_to TIMESTAMP 
                COMMENT 'End timestamp for this version of the store record. Business: NULL indicates this is the current version. Non-NULL indicates historical record. Technical: SCD Type 2 field, set to next version effective_from when superseded.',
            
            is_current BOOLEAN NOT NULL 
                COMMENT 'Flag indicating if this is the current active version. Business: TRUE for current store attributes, FALSE for historical records. Used with WHERE is_current = true to get latest state. Technical: SCD Type 2 flag, updated to FALSE when new version created.',
            
            -- Audit timestamps
            record_created_timestamp TIMESTAMP 
                COMMENT 'Timestamp when this record was first inserted into the Gold layer. Business: Audit field for data lineage and troubleshooting. Technical: Set once at INSERT time, never updated.',
            
            record_updated_timestamp TIMESTAMP 
                COMMENT 'Timestamp when this record was last modified. Business: Audit field showing data freshness and update history. Technical: Updated on every MERGE operation that modifies the record.'
        )
        USING DELTA
        CLUSTER BY AUTO
        TBLPROPERTIES (
            'delta.enableChangeDataFeed' = 'true',
            'delta.enableRowTracking' = 'true',
            'delta.enableDeletionVectors' = 'true',
            'delta.autoOptimize.autoCompact' = 'true',
            'delta.autoOptimize.optimizeWrite' = 'true',
            'quality' = 'gold',
            'layer' = 'gold',
            'source_table' = 'silver_store_dim',
            'domain' = 'retail',
            'entity_type' = 'dimension',
            'scd_type' = '2',
            'contains_pii' = 'true',
            'data_classification' = 'confidential',
            'business_owner' = 'Retail Operations',
            'technical_owner' = 'Data Engineering'
        )
        COMMENT 'Gold layer conformed store dimension with SCD Type 2 history tracking. Business: Maintains complete store lifecycle history including address changes, status updates, and operational attributes. Each store version tracked separately for point-in-time analysis. Technical: Slowly Changing Dimension Type 2 implementation with effective dating, surrogate keys enable proper fact table joins to historical store states.'
    """)
```

### Fact Table
```python
def create_fact_sales_daily(spark: SparkSession, catalog: str, schema: str):
    """Create fact_sales_daily table."""
    table_name = f"{catalog}.{schema}.fact_sales_daily"
    
    spark.sql(f"""
        CREATE OR REPLACE TABLE {table_name} (
            -- Surrogate foreign keys (joins to dimensions)
            store_key STRING NOT NULL 
                COMMENT 'Surrogate foreign key to dim_store. Business: Joins to store dimension for store attributes and location analysis. Technical: References dim_store.store_key (PRIMARY KEY), enables fast hash joins.',
            
            product_key STRING NOT NULL 
                COMMENT 'Surrogate foreign key to dim_product. Business: Joins to product dimension for product attributes and category analysis. Technical: References dim_product.product_key (PRIMARY KEY), enables fast hash joins.',
            
            date_key INT NOT NULL 
                COMMENT 'Integer surrogate foreign key to dim_date in YYYYMMDD format. Business: Joins to date dimension for calendar attributes and time-series analysis. Technical: Integer FK enables faster joins than date comparisons, references dim_date.date_key (PRIMARY KEY).',
            
            -- Denormalized business keys (human readability)
            store_number STRING NOT NULL 
                COMMENT 'Store business key for human readability. Business: Natural store identifier used by operations, included for query convenience and readability. Technical: Denormalized from dim_store, matches store_key but human-friendly.',
            
            upc_code STRING NOT NULL 
                COMMENT 'Product UPC code for human readability. Business: Natural product identifier scanned at POS, included for query convenience and readability. Technical: Denormalized from dim_product, matches product_key but human-friendly.',
            
            transaction_date DATE NOT NULL 
                COMMENT 'Transaction calendar date for human readability. Business: Natural date value for filtering and display, included for query convenience. Technical: Denormalized from dim_date, matches date_key but human-friendly.',
            
            -- Measures
            net_revenue DECIMAL(18,2) 
                COMMENT 'Net revenue after subtracting returns from gross revenue. Business: The actual revenue realized from sales, primary KPI for financial reporting. Technical: gross_revenue - return_amount, represents true daily sales value.',
            
            net_units BIGINT 
                COMMENT 'Net units sold after subtracting returns. Business: The actual unit demand after accounting for returns, used for true inventory consumption analysis. Technical: units_sold - units_returned.',
            
            transaction_count BIGINT 
                COMMENT 'Total number of sale transactions. Business: Count of all sales events including both sales and returns. Used for traffic analysis and basket metrics. Technical: COUNT(DISTINCT transaction_id).',
            
            -- Audit timestamps
            record_created_timestamp TIMESTAMP 
                COMMENT 'Timestamp when this daily aggregate was first created. Business: Audit field for data lineage and pipeline troubleshooting. Technical: Set during initial MERGE INSERT, remains constant.',
            
            record_updated_timestamp TIMESTAMP 
                COMMENT 'Timestamp when this daily aggregate was last refreshed. Business: Shows data freshness for this date, useful for validating late-arriving transactions were included. Technical: Updated on every MERGE operation that touches this record.'
        )
        USING DELTA
        CLUSTER BY AUTO
        TBLPROPERTIES (
            'delta.enableChangeDataFeed' = 'true',
            'delta.enableRowTracking' = 'true',
            'delta.enableDeletionVectors' = 'true',
            'delta.autoOptimize.autoCompact' = 'true',
            'delta.autoOptimize.optimizeWrite' = 'true',
            'quality' = 'gold',
            'layer' = 'gold',
            'source_table' = 'silver_transactions',
            'domain' = 'sales',
            'entity_type' = 'fact',
            'grain' = 'daily_store_product',
            'contains_pii' = 'false',
            'data_classification' = 'confidential',
            'business_owner' = 'Sales Analytics',
            'technical_owner' = 'Data Engineering'
        )
        COMMENT 'Gold layer daily sales fact table with pre-aggregated metrics at store-product-day grain. Business: Primary source for sales performance reporting including revenue, units, discounts, returns, and customer loyalty metrics. Aggregated from transaction-level Silver data for fast query performance. Used for dashboards, executive reporting, and sales analysis. Technical: Grain is one row per store-product-date combination. Pre-aggregated measures eliminate need for transaction-level scans, surrogate keys enable fast dimension joins.'
    """)
```

## Validation Checklist

When creating or updating Gold layer tables:

### Naming Conventions
- [ ] Surrogate keys use `{entity}_key` pattern
- [ ] Business keys use natural terminology
- [ ] Measures use descriptive names (no cryptic abbreviations)
- [ ] Percentages end with `_pct`
- [ ] Boolean flags start with `is_` or action verb
- [ ] Timestamps end with `_timestamp`
- [ ] SCD fields use `effective_from`, `effective_to`, `is_current`

### Column Documentation
- [ ] Every column has a comment
- [ ] Comments follow: `[Definition]. Business: [context]. Technical: [details].` format
- [ ] Surrogate keys document hash generation method
- [ ] Business keys document source and immutability
- [ ] Foreign keys document referenced table and column
- [ ] Measures document calculation formula
- [ ] Flags document TRUE/FALSE meanings
- [ ] Timestamps document update behavior

### Table Documentation
- [ ] Table comment includes layer and grain
- [ ] Table comment explains business use cases
- [ ] Table comment describes technical implementation
- [ ] TBLPROPERTIES includes all required fields
- [ ] `grain` property set for fact tables
- [ ] `scd_type` property set for dimensions
- [ ] `CLUSTER BY AUTO` specified

### Primary and Foreign Keys
- [ ] Surrogate keys are NOT NULL
- [ ] PRIMARY KEYs defined on surrogate keys
- [ ] FOREIGN KEYs reference surrogate PKs
- [ ] Facts have composite PKs matching grain
- [ ] UNIQUE constraints on business keys (where applicable)

## Common Mistakes to Avoid

### ❌ Mistake 1: Using "LLM:" prefix
```python
# OLD PATTERN (Don't use)
store_key STRING NOT NULL COMMENT 'LLM: Surrogate key (unique per version)'
```

### ✅ Correct: Natural dual-purpose description
```python
store_key STRING NOT NULL COMMENT 'Surrogate key uniquely identifying each version of a store record. Business: Used for joining fact tables to dimension. Technical: MD5 hash generated from store_id and processed_timestamp to ensure uniqueness across SCD Type 2 versions.'
```

### ❌ Mistake 2: Business key as PRIMARY KEY
```python
# WRONG: Breaks dimensional modeling
CREATE TABLE dim_store (
    store_key STRING NOT NULL,
    store_number STRING NOT NULL PRIMARY KEY,  -- ❌ Wrong
    ...
)
```

### ✅ Correct: Surrogate key as PRIMARY KEY
```python
CREATE TABLE dim_store (
    store_key STRING NOT NULL,
    store_number STRING NOT NULL,
    ...
    CONSTRAINT pk_dim_store PRIMARY KEY (store_key) NOT ENFORCED,  -- ✅ Correct
    CONSTRAINT uk_store_number UNIQUE (store_number) NOT ENFORCED  -- Business key is UNIQUE
)
```

### ❌ Mistake 3: Missing business context
```python
# Too technical, no business value explained
net_revenue DECIMAL(18,2) COMMENT 'Technical: gross_revenue - return_amount'
```

### ✅ Correct: Business and technical context
```python
net_revenue DECIMAL(18,2) COMMENT 'Net revenue after subtracting returns from gross revenue. Business: The actual revenue realized from sales, primary KPI for financial reporting. Technical: gross_revenue - return_amount, represents true daily sales value.'
```

### ❌ Mistake 4: Vague table comment
```python
COMMENT 'Gold layer sales data'
```

### ✅ Correct: Comprehensive table comment
```python
COMMENT 'Gold layer daily sales fact table with pre-aggregated metrics at store-product-day grain. Business: Primary source for sales performance reporting including revenue, units, discounts, returns, and customer loyalty metrics. Aggregated from transaction-level Silver data for fast query performance. Used for dashboards, executive reporting, and sales analysis. Technical: Grain is one row per store-product-date combination. Pre-aggregated measures eliminate need for transaction-level scans, surrogate keys enable fast dimension joins.'
```

### ❌ Mistake 5: Missing grain in TBLPROPERTIES
```python
# Fact table without grain
TBLPROPERTIES (
    'layer' = 'gold',
    'entity_type' = 'fact'
    # Missing 'grain' property
)
```

### ✅ Correct: Grain documented
```python
TBLPROPERTIES (
    'layer' = 'gold',
    'entity_type' = 'fact',
    'grain' = 'daily_store_product'  -- ✅ Clear grain definition
)
```

## Benefits

### For Business Users
- ✅ Clear explanations without technical jargon first
- ✅ Business use cases and decision context
- ✅ No need to understand implementation details
- ✅ Self-service data discovery

### For Technical Users
- ✅ Implementation details and calculation logic
- ✅ Source system information
- ✅ Performance implications
- ✅ Data quality considerations

### For LLMs (Genie, AI/BI)
- ✅ Rich semantic context for natural language queries
- ✅ Clear relationships between fields
- ✅ Business logic for metric calculations
- ✅ Domain knowledge for accurate query generation

### For Data Governance
- ✅ Complete field documentation for compliance
- ✅ Clear lineage and source information
- ✅ Privacy and security context
- ✅ Ownership and stewardship clarity

## Implementation Guidance (CRITICAL)

### Design Documentation vs Implementation Documentation

**Key Learning:** Schema documentation (columns, types, constraints) is necessary but insufficient for implementation. You must also document:

1. **Actual Silver table names** (not just Bronze sources)
2. **Join requirements** for denormalized fields
3. **Column provenance** (which table each column comes from)
4. **Transformation logic** beyond simple mappings

### Silver Table Naming Conventions

**CRITICAL: Silver DLT tables DO NOT use `_dim` or `_fact` suffixes.**

#### ❌ WRONG: Assuming suffix patterns
```python
# Implementation assumed:
silver_table = f"{catalog}.{silver_schema}.silver_user_dim"      # ❌ Wrong
silver_table = f"{catalog}.{silver_schema}.silver_property_dim"  # ❌ Wrong
```

#### ✅ CORRECT: Actual Silver DLT naming
```python
# Silver DLT actually creates:
silver_table = f"{catalog}.{silver_schema}.silver_users"         # ✅ Correct
silver_table = f"{catalog}.{silver_schema}.silver_properties"    # ✅ Correct
```

**Pattern:**
- Bronze: `users`, `hosts`, `properties`, `bookings`
- Silver: `silver_users`, `silver_hosts`, `silver_properties`, `silver_bookings`
- Gold: `dim_user`, `dim_host`, `dim_property`, `fact_booking_detail`

### Documenting Silver Sources in YAML

**Enhance your YAML files to include actual Silver table names:**

```yaml
# BEFORE (insufficient)
table_name: dim_user
bronze_source: users
# ❌ Missing: actual Silver table name

# AFTER (complete)
table_name: dim_user
bronze_source: users
silver_source: silver_users  # ← ADD THIS
lineage:
  bronze:
    schema: ${bronze_schema}
    table: users
  silver:
    schema: ${silver_schema}
    table: silver_users  # ← Explicit table name
```

### Join Requirements for Denormalized Fields

**Problem:** Fact tables often include FK fields that don't exist in the base Silver table and require joins.

**Example:** `fact_booking_detail` needs `host_id` and `destination_id`, but `silver_bookings` doesn't have these fields.

#### Required Join Documentation

```yaml
table_name: fact_booking_detail
bronze_source: bookings, payments
silver_source: silver_bookings

# ✨ ADD THIS: Document required joins
silver_lineage:
  base_table:
    name: silver_bookings
    schema: ${silver_schema}
  
  dimension_joins:  # For denormalized FK fields
    - table: silver_users
      join_type: left
      join_on: bookings.user_id = users.user_id
      columns_sourced: [is_business]
      purpose: "Get user business flag for is_business_booking"
    
    - table: silver_properties
      join_type: left
      join_on: bookings.property_id = properties.property_id
      columns_sourced: [host_id, destination_id]
      purpose: "Denormalize property dimensions into fact for fast queries"
  
  fact_joins:  # For aggregation sources
    - table: silver_payments
      join_type: left
      join_on: bookings.booking_id = payments.booking_id
      columns_sourced: [amount, payment_method]
      purpose: "Get most recent successful payment details"

# ✨ ADD THIS: Column-level source mapping
column_derivation:
  # Direct columns (from base table)
  - column: booking_id
    source: silver_bookings.booking_id
    transformation: direct
  
  # Joined columns (from dimensions)
  - column: host_id
    source: silver_properties.host_id
    transformation: join
    join_path: bookings.property_id = properties.property_id
  
  - column: destination_id
    source: silver_properties.destination_id
    transformation: join
    join_path: bookings.property_id = properties.property_id
  
  # Derived columns (calculated)
  - column: is_business_booking
    source: silver_users.is_business
    transformation: COALESCE(is_business, FALSE)
    join_path: bookings.user_id = users.user_id
```

### Pre-Implementation Validation

**ALWAYS perform these checks before writing merge code:**

#### Step 1: List Actual Silver Tables
```bash
# Get actual table names (don't assume!)
databricks sql "SHOW TABLES IN {catalog}.{silver_schema}"
```

#### Step 2: Verify Column Availability
```sql
-- Check if required columns exist
DESCRIBE TABLE {catalog}.{silver_schema}.silver_bookings;

-- Do we have host_id? destination_id? is_business?
-- If not, which tables do we need to join?
```

#### Step 3: Create Column Source Map

For each Gold table, document before coding:

| Gold Column | Source | Join Required? | Transformation |
|-------------|--------|----------------|----------------|
| booking_id | silver_bookings.booking_id | No | Direct |
| host_id | silver_properties.host_id | Yes (via property_id) | Join |
| destination_id | silver_properties.destination_id | Yes (via property_id) | Join |
| is_business_booking | silver_users.is_business | Yes (via user_id) | Join + COALESCE |
| nights_booked | check_out - check_in | No | Calculate |

**This map prevents 80% of column errors!**

#### Step 4: Validate Schema Variables
```python
# Verify dev mode prefixes in databricks.yml
print(f"Gold schema variable: {gold_schema}")
# Expected in dev: dev_prashanth_subrahmanyam_wanderbricks_gold
# NOT: wanderbricks_gold
```

### Implementation Pattern with Validation

```python
def merge_fact_booking_detail(spark: SparkSession, catalog: str, silver_schema: str, gold_schema: str):
    """Merge fact_booking_detail from Silver to Gold with proper joins."""
    
    # 1. Validate Silver sources exist
    silver_tables = {
        'bookings': f"{catalog}.{silver_schema}.silver_bookings",
        'users': f"{catalog}.{silver_schema}.silver_users",
        'properties': f"{catalog}.{silver_schema}.silver_properties",
        'payments': f"{catalog}.{silver_schema}.silver_payments"
    }
    
    for name, table in silver_tables.items():
        try:
            spark.table(table)
        except Exception:
            raise ValueError(f"Required Silver table not found: {table}")
    
    # 2. Read Silver tables
    bookings = spark.table(silver_tables['bookings'])
    users = spark.table(silver_tables['users']).select('user_id', 'is_business')
    properties = spark.table(silver_tables['properties']).select('property_id', 'host_id', 'destination_id')
    payments = spark.table(silver_tables['payments'])
    
    # 3. Join to get denormalized fields
    fact_df = (
        bookings
        .join(users, on='user_id', how='left')  # Get is_business
        .join(properties, on='property_id', how='left')  # Get host_id, destination_id
        .join(payments, on='booking_id', how='left')  # Get payment details
        .withColumn('is_business_booking', coalesce(col('is_business'), lit(False)))
        .select(
            'booking_id',
            'user_id',
            'property_id',
            'host_id',  # ← From properties join
            'destination_id',  # ← From properties join
            'is_business_booking',  # ← From users join
            # ... other columns
        )
    )
    
    # 4. MERGE into Gold
    gold_table = f"{catalog}.{gold_schema}.fact_booking_detail"
    # ... merge logic
```

### Common Mistakes to Avoid

#### ❌ Mistake 1: Assuming table naming conventions
```python
# WRONG - assumes _dim suffix
silver_table = f"{catalog}.{silver_schema}.silver_user_dim"
```

#### ✅ Correct: Verify first, then code
```python
# List tables to confirm naming
tables = spark.sql(f"SHOW TABLES IN {catalog}.{silver_schema}").collect()
# Confirm: silver_users (no _dim suffix)

silver_table = f"{catalog}.{silver_schema}.silver_users"
```

#### ❌ Mistake 2: Assuming columns exist in base table
```python
# WRONG - host_id doesn't exist in bookings
fact_df = bookings.select('booking_id', 'host_id')
# Error: Column 'host_id' does not exist
```

#### ✅ Correct: Document and implement joins
```python
# Join to get denormalized fields
properties = spark.table('silver_properties').select('property_id', 'host_id')
fact_df = bookings.join(properties, on='property_id', how='left')
```

#### ❌ Mistake 3: Using wrong schema name in dev
```python
# WRONG - missing dev prefix
gold_schema = "wanderbricks_gold"  # In dev, this is wrong!
```

#### ✅ Correct: Use schema variable from bundle
```python
# Get from bundle parameter (includes dev prefix)
gold_schema = dbutils.widgets.get("gold_schema")
# In dev: dev_prashanth_subrahmanyam_wanderbricks_gold
# In prod: wanderbricks_gold
```

### Validation Checklist for Implementation

Before deploying Gold merge scripts:
- [ ] Listed actual Silver table names (verified, not assumed)
- [ ] Created column source map showing which Silver table provides each column
- [ ] Identified all required joins for denormalized fields
- [ ] Validated schema variables include dev prefixes
- [ ] Tested one merge function before scaling to all tables
- [ ] Added error handling for missing Silver tables

### ROI of Pre-Implementation Validation

| Activity | Time Investment | Errors Prevented |
|----------|----------------|------------------|
| List Silver tables | 2 min | Table naming errors |
| Create column map | 10 min | Column source errors, missing join errors |
| Validate schema vars | 2 min | Schema name errors |
| **Total** | **15 min** | **80% of deployment issues** |

**Time saved:** 30-60 minutes of debugging per deployment

### Lessons Learned

1. **Never assume naming conventions** - Verify actual table names first
2. **Document Silver lineage explicitly** - Include actual table names in YAML
3. **Map column sources before coding** - Know which table each column comes from
4. **Validate join requirements** - Denormalized fields require explicit joins
5. **Test schema variables in dev** - Confirm dev prefixes are applied

## References

### Dimensional Modeling
- [Kimball Dimensional Modeling](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/)
- [Star Schema Design](https://docs.databricks.com/lakehouse-architecture/medallion.html)

### Unity Catalog
- [Unity Catalog Constraints](https://docs.databricks.com/data-governance/unity-catalog/constraints.html)
- [Primary and Foreign Keys](https://docs.databricks.com/tables/constraints.html#declare-primary-key-and-foreign-key-relationships)

### Delta Lake
- [Delta Table Properties](https://docs.delta.io/latest/table-properties.html)
- [Automatic Clustering](https://docs.databricks.com/aws/en/delta/clustering#enable-or-disable-automatic-liquid-clustering)

### Project Documentation
- [Gold Layer README](../../docs/gold/GOLD_LAYER_README.md)
- [Gold Compliance Checklist](../../docs/gold/GOLD_COMPLIANCE_CHECKLIST.md)
- [Unity Catalog Constraints Rule](unity-catalog-constraints.mdc)
- [Gold Layer Deployment Post-Mortem](../../docs/troubleshooting/2025-12-10-gold-layer-deployment-postmortem.md)
