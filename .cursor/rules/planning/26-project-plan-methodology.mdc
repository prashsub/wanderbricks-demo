---
description: Comprehensive methodology for creating multi-phase project plans for Databricks data platform solutions
globs:
  - "plans/**/*.md"
  - "docs/**/*plan*.md"
  - "docs/**/*roadmap*.md"
alwaysApply: false
---

# Project Plan Methodology for Databricks Solutions

## Pattern Recognition

This rule documents the comprehensive methodology for creating multi-phase project plans for Databricks data platform solutions. The patterns were discovered and refined during the Databricks Health Monitor project planning process.

**Key Assumption:** Planning starts AFTER Bronze ingestion and Gold layer design are complete. These are prerequisites, not phases.

---

## When to Apply This Rule

Apply this methodology when:
- Creating architectural plans for Databricks data platform projects
- Building observability/monitoring solutions using system tables
- Planning multi-artifact solutions (TVFs, Metric Views, Dashboards, etc.)
- Developing agent-based frameworks for platform management
- Creating frontend applications for data platform interaction

---

## Plan Structure Framework

### Prerequisites (Not Numbered Phases)

Before planning begins, these must be complete:

| Prerequisite | Description | Status |
|--------------|-------------|--------|
| Bronze Layer | Raw data ingestion from source systems | ‚úÖ Complete |
| Silver Layer | DLT streaming with data quality | ‚úÖ Complete |
| Gold Layer | Dimensional model (star schema) | ‚úÖ Complete |

### Standard Project Phases

```
plans/
‚îú‚îÄ‚îÄ README.md                              # Index and overview
‚îú‚îÄ‚îÄ prerequisites.md                       # Bronze/Silver/Gold summary (optional)
‚îú‚îÄ‚îÄ phase1-use-cases.md                    # Analytics artifacts (master)
‚îÇ   ‚îú‚îÄ‚îÄ phase1-addendum-1.1-ml-models.md   # Machine Learning
‚îÇ   ‚îú‚îÄ‚îÄ phase1-addendum-1.2-tvfs.md        # Table-Valued Functions
‚îÇ   ‚îú‚îÄ‚îÄ phase1-addendum-1.3-metric-views.md # UC Metric Views
‚îÇ   ‚îú‚îÄ‚îÄ phase1-addendum-1.4-lakehouse-monitoring.md # Monitoring
‚îÇ   ‚îú‚îÄ‚îÄ phase1-addendum-1.5-ai-bi-dashboards.md # Dashboards
‚îÇ   ‚îú‚îÄ‚îÄ phase1-addendum-1.6-genie-spaces.md # Natural Language
‚îÇ   ‚îî‚îÄ‚îÄ phase1-addendum-1.7-alerting-framework.md # Alerting
‚îú‚îÄ‚îÄ phase2-agent-framework.md              # AI Agents
‚îî‚îÄ‚îÄ phase3-frontend-app.md                 # User Interface
```

### Phase Dependencies

```
Prerequisites (Bronze ‚Üí Silver ‚Üí Gold) ‚Üí Phase 1 (Use Cases) ‚Üí Phase 2 (Agents) ‚Üí Phase 3 (Frontend)
         [COMPLETE]                               ‚Üì
                                           All Addendums
```

---

## Agent Domain Framework

### Core Principle

**ALL artifacts across ALL phases MUST be organized by Agent Domain.** This ensures:
- Consistent categorization across 100+ artifacts
- Clear ownership by future AI agents
- Easy discoverability for users
- Aligned tooling for each domain

### Standard Agent Domains

| Domain | Icon | Focus Area | Key Gold Tables |
|--------|------|------------|-----------------|
| **Cost** | üí∞ | FinOps, budgets, chargeback | `fact_usage`, `dim_sku`, `commit_configurations` |
| **Security** | üîí | Access audit, compliance | `fact_audit_events`, `fact_table_lineage` |
| **Performance** | ‚ö° | Query optimization, capacity | `fact_query_history`, `fact_node_timeline` |
| **Reliability** | üîÑ | Job health, SLAs | `fact_job_run_timeline`, `dim_job` |
| **Quality** | ‚úÖ | Data quality, governance | `fact_data_quality_monitoring_table_results` |

### Agent Domain Application

Every artifact (TVF, Metric View, Dashboard, Alert, ML Model, Monitor, Genie Space) must:
1. Be tagged with its Agent Domain
2. Use the domain's Gold tables
3. Answer domain-specific questions
4. Be grouped with related domain artifacts in documentation

**Example Pattern:**

```markdown
## üí∞ Cost Agent: get_top_cost_contributors

**Agent Domain:** üí∞ Cost
**Gold Tables:** `fact_usage`, `dim_workspace`
**Business Questions:** "What are the top cost drivers?"
```

---

## Agent Layer Architecture Pattern

### Core Principle: Agents Use Genie Spaces as Query Interface

**AI Agents DO NOT query data assets directly.** Instead, they use Genie Spaces as their natural language query interface. Genie Spaces translate natural language to SQL and route to appropriate tools (TVFs, Metric Views, ML Models).

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     USERS (Natural Language)                             ‚îÇ
‚îÇ  "Why did costs spike last Tuesday?"                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              PHASE 2: AI AGENT LAYER (LangChain/LangGraph)              ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ ORCHESTRATOR AGENT                                     ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Intent classification (cost, security, performance)  ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Routes to specialized agents                         ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Coordinates multi-agent workflows                    ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Uses: Unified Health Monitor Genie Space             ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ                               ‚îÇ                                          ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ   ‚ñº                           ‚ñº                           ‚ñº            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ Cost    ‚îÇ          ‚îÇ Security   ‚îÇ           ‚îÇ Performance ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ Agent   ‚îÇ          ‚îÇ Agent      ‚îÇ           ‚îÇ Agent       ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ          ‚îÇ            ‚îÇ           ‚îÇ             ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ Uses:   ‚îÇ          ‚îÇ Uses:      ‚îÇ           ‚îÇ Uses:       ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ Cost    ‚îÇ          ‚îÇ Security   ‚îÇ           ‚îÇ Performance ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ Intel   ‚îÇ          ‚îÇ Auditor    ‚îÇ           ‚îÇ Analyzer    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ Genie   ‚îÇ          ‚îÇ Genie      ‚îÇ           ‚îÇ Genie       ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚îÇ Natural Language Queries
                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            PHASE 1.6: GENIE SPACES (NL Query Execution)                 ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îÇ  ‚Ä¢ Translates natural language ‚Üí SQL                                    ‚îÇ
‚îÇ  ‚Ä¢ Understands domain terminology and synonyms                          ‚îÇ
‚îÇ  ‚Ä¢ Routes to appropriate tools (TVFs, Metric Views, ML)                ‚îÇ
‚îÇ  ‚Ä¢ Returns structured results to agents                                 ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Cost Intel ‚îÇ  ‚îÇ Security   ‚îÇ  ‚îÇ Performance‚îÇ  ‚îÇ Job Health ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Genie     ‚îÇ  ‚îÇ Auditor    ‚îÇ  ‚îÇ Analyzer   ‚îÇ  ‚îÇ Monitor    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ 15 TVFs   ‚îÇ  ‚îÇ 10 TVFs    ‚îÇ  ‚îÇ 16 TVFs    ‚îÇ  ‚îÇ 12 TVFs    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ 2 MVs     ‚îÇ  ‚îÇ 2 MVs      ‚îÇ  ‚îÇ 3 MVs      ‚îÇ  ‚îÇ 1 MV       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ 6 ML      ‚îÇ  ‚îÇ 4 ML       ‚îÇ  ‚îÇ 7 ML       ‚îÇ  ‚îÇ 5 ML       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚îÇ SQL + Function Calls
                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                PHASE 1: DATA ASSETS (Agent Tools)                        ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ METRIC VIEWS (Pre-aggregated analytics - use FIRST)             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ 10 metric views with 30+ measures each                          ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ TABLE-VALUED FUNCTIONS (Parameterized queries)                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ 60 TVFs with business logic encapsulation                       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ ML PREDICTIONS (ML-powered insights)                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ 25 ML models with prediction tables                             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ LAKEHOUSE MONITORS (Drift detection)                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ 8 monitors with profile + drift metrics                         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚îÇ SQL Queries
                                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              PREREQUISITES: GOLD LAYER (Foundation)                      ‚îÇ
‚îÇ              38 dimension + fact tables (star schema)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Genie Space ‚Üí Agent Mapping

Each specialized agent has a corresponding Genie Space that serves as its query interface:

| Agent | Genie Space | Agent Purpose | Tools (via Genie) |
|-------|-------------|---------------|-------------------|
| üí∞ **Cost Agent** | Cost Intelligence | Analyze costs, forecast spending, optimize resources | 15 TVFs, 2 MVs, 6 ML |
| üîí **Security Agent** | Security Auditor | Monitor audit logs, detect threats, ensure compliance | 10 TVFs, 2 MVs, 4 ML |
| ‚ö° **Performance Agent** | Performance Analyzer | Monitor job/query/cluster performance, identify bottlenecks | 16 TVFs, 3 MVs, 7 ML |
| üîÑ **Reliability Agent** | Job Health Monitor | Track SLAs, detect incidents, analyze failures | 12 TVFs, 1 MV, 5 ML |
| ‚úÖ **Data Quality Agent** | Data Quality Monitor | Ensure data quality, track lineage, enforce governance | 7 TVFs, 2 MVs, 3 ML |
| ü§ñ **ML Ops Agent** | ML Intelligence | Monitor experiments, model performance, serving endpoints | Integrated across spaces |
| üåê **Orchestrator Agent** | Unified Health Monitor | Route queries, coordinate multi-agent workflows | All 60 TVFs, 10 MVs, 25 ML |

### Agent Query Flow

**Example: User asks Cost Agent about cost spike**

```
1. USER: "Why did costs spike last Tuesday?"
              ‚îÇ
              ‚ñº
2. ORCHESTRATOR AGENT: Intent classification ‚Üí "cost"
              ‚îÇ
              ‚ñº
3. COST AGENT: Uses Cost Intelligence Genie Space
              ‚îÇ
              ‚ñº
4. GENIE SPACE: Translates to SQL/TVF calls
              ‚îÇ
              ‚îú‚îÄ‚îÄ get_cost_trend_by_sku TVF (14-day trend)
              ‚îú‚îÄ‚îÄ cost_analytics Metric View (aggregated data)
              ‚îî‚îÄ‚îÄ cost_anomaly_predictions ML Table (anomaly check)
              ‚îÇ
              ‚ñº
5. DATA ASSETS: Execute queries, return results
              ‚îÇ
              ‚ñº
6. COST AGENT: Synthesizes results with context
              ‚îÇ
              ‚ñº
7. RESPONSE: "Costs increased 35% on Tuesday. ML detected anomaly.
              Root cause: 3 new pipelines launched in 'data-eng' workspace.
              Recommendation: Review pipeline efficiency."
```

### Why Genie Spaces (Not Direct SQL)?

| Without Genie Spaces | With Genie Spaces |
|---------------------|-------------------|
| Agents must write SQL | Agents use natural language |
| Agents must know schema | Genie understands semantics |
| Agents must handle synonyms | Genie handles synonyms |
| Agents must select right tool | Genie routes to best tool |
| Complex agent development | Simpler agent development |
| Hard to maintain | Easy to update instructions |

### Multi-Agent Workflow Pattern

For complex queries spanning multiple domains:

```python
# User: "Why did costs spike AND were there job failures?"
                            ‚îÇ
                            ‚ñº
ORCHESTRATOR AGENT:
  1. Intent classification ‚Üí ["cost", "reliability"]
  2. Fork to multiple agents (parallel)
                            ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚ñº                                   ‚ñº
    COST AGENT                        RELIABILITY AGENT
          ‚îÇ                                   ‚îÇ
          ‚ñº                                   ‚ñº
    Cost Intelligence Genie           Job Health Monitor Genie
          ‚îÇ                                   ‚îÇ
          ‚ñº                                   ‚ñº
    get_cost_trend_by_sku()           get_failed_jobs()
    cost_anomaly_predictions          job_failure_predictions
          ‚îÇ                                   ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚ñº
ORCHESTRATOR AGENT:
  3. Correlate results
  4. Check: Did failures cause cost spike?
  5. Synthesize unified response
                            ‚îÇ
                            ‚ñº
RESPONSE: "Costs spiked 35% on Tuesday. 5 job failures detected.
           Correlation: Failed jobs retried 12x, causing extra compute.
           Root cause: Cluster timeout in 'data-eng' workspace.
           Actions: Fix cluster config, review retry policy."
```

### Deployment Order (Critical!)

**Genie Spaces MUST be deployed BEFORE agents can use them.**

```
Phase 0: Prerequisites (Complete)
    ‚îî‚îÄ‚îÄ Bronze ‚Üí Silver ‚Üí Gold Layer

Phase 1: Data Assets (Deploy First)
    ‚îú‚îÄ‚îÄ 1.1: ML Models (25 models ‚Üí prediction tables)
    ‚îú‚îÄ‚îÄ 1.2: TVFs (60 functions)
    ‚îú‚îÄ‚îÄ 1.3: Metric Views (10 views)
    ‚îú‚îÄ‚îÄ 1.4: Lakehouse Monitors (8 monitors)
    ‚îú‚îÄ‚îÄ 1.5: AI/BI Dashboards (11 dashboards)
    ‚îú‚îÄ‚îÄ 1.6: Genie Spaces (7 spaces) ‚Üê Critical for agents
    ‚îî‚îÄ‚îÄ 1.7: Alerting (40 alerts)

Phase 2: Agent Framework (Deploy After Genie Spaces)
    ‚îú‚îÄ‚îÄ 2.1: Agent framework setup (LangChain/LangGraph)
    ‚îú‚îÄ‚îÄ 2.2: Specialized agents (6 agents)
    ‚îú‚îÄ‚îÄ 2.3: Orchestrator agent
    ‚îî‚îÄ‚îÄ 2.4: Deployment to Model Serving

Phase 3: Frontend (Deploy Last)
    ‚îî‚îÄ‚îÄ Unified UI consuming agents
```

### Agent Integration Testing

**Three-level testing strategy:**

| Level | What to Test | When to Test |
|-------|--------------|--------------|
| **L1: Genie Standalone** | Genie Space returns correct results for benchmark questions | After Genie deployment |
| **L2: Agent Integration** | Agent successfully uses Genie and formats response | After agent deployment |
| **L3: Multi-Agent** | Orchestrator coordinates multiple agents for complex queries | After all agents deployed |

### Genie Space Configuration for Agents

**Each Genie Space must include agent-optimized configuration:**

```yaml
# General Instructions (‚â§20 lines for Genie to process)
## Query Routing
- Cost questions ‚Üí cost_analytics metric view + cost TVFs
- Job questions ‚Üí job_performance metric view + job TVFs
- Query questions ‚Üí query_performance metric view + query TVFs

## Tool Selection Priority
1. Metric Views (fastest, pre-aggregated)
2. TVFs (parameterized, business logic)
3. ML Predictions (anomalies, forecasts)
4. Gold Tables (only if above insufficient)

## Response Format
- Include time context
- Format currency as USD with 2 decimals
- Format percentages with 1 decimal
- Provide recommendations when applicable
```

### Success Metrics for Agent-Genie Integration

| Metric | Genie Only | With Agents | Target |
|--------|-----------|-------------|--------|
| User adoption | 50-100 power users | 500+ all users | 5-10x |
| Query success rate | 85% | 95% (agents retry) | +10% |
| Time to insight | 2-5 minutes | 10-30 seconds | 10x faster |
| Proactive alerts | 0 (reactive) | 100+ daily | ‚àû |
| Complex analysis | 10% of queries | 40% of queries | 4x |

---

## Plan Document Template

### Standard Structure for Each Phase

```markdown
# Phase N: [Phase Name]

## Overview

**Status:** üìã Planned | üîß In Progress | ‚úÖ Complete  
**Dependencies:** [List dependencies]  
**Estimated Effort:** [Duration]  
**Reference:** [Official docs or cursor rules]

---

## Purpose

[2-3 sentences explaining why this phase exists]

---

## [Domain-Specific Sections]

### üí∞ Cost Agent: [Artifact Name]

[Artifact details organized by agent domain]

### üîí Security Agent: [Artifact Name]

[Continue for all domains]

---

## Implementation Details

[Code examples, SQL, YAML configurations]

---

## Success Criteria

| Criteria | Target |
|----------|--------|
| [Metric] | [Value] |

---

## References

- [Official Docs]
- [Cursor Rules]
```

---

## Enrichment Methodology

### Source Categories for Enrichment

When enriching plans, gather information from these sources (in priority order):

1. **Official Documentation** (highest priority)
   - Databricks docs (docs.databricks.com)
   - Microsoft Learn MCP tool
   - Context7 MCP for library docs

2. **Reference Dashboards**
   - Extract SQL query patterns from `.lvdash.json` files
   - Identify visualization types and KPIs
   - Note filtering and slicing patterns

3. **Community Resources**
   - Blog posts (data engineering blogs)
   - GitHub repositories (dbdemos, etc.)
   - Sample solutions

4. **User Requirements**
   - Specific use cases provided by user
   - Business-specific terminology
   - Custom tag keys and values

### Dashboard Pattern Extraction Process

When provided with dashboard JSON files:

1. **Read the JSON file** to extract:
   - Dataset queries (SQL)
   - Visualization configurations
   - Filter parameters
   - Dashboard title and purpose

2. **Categorize patterns by Agent Domain**

3. **Convert queries to Gold layer references**
   ```sql
   -- FROM dashboard (system tables)
   FROM system.billing.usage
   
   -- TO plan (Gold layer)
   FROM ${catalog}.${gold_schema}.fact_usage
   ```

4. **Document the pattern** with:
   - Source dashboard name
   - Business question answered
   - Visualization type
   - Agent domain classification

### Enrichment Workflow

```
1. Receive reference materials (blogs, repos, dashboards)
                    ‚Üì
2. Extract patterns and queries
                    ‚Üì
3. Categorize by Agent Domain
                    ‚Üì
4. Convert to Gold layer references
                    ‚Üì
5. Add to appropriate addendum
                    ‚Üì
6. Update summary tables and cross-references
```

---

## User Requirement Integration

### Process for Adding User-Specific Use Cases

When users provide specific requirements:

1. **Understand the Business Need**
   - What question are they trying to answer?
   - What decisions will this inform?
   - Who is the end user?

2. **Identify Required Artifacts**
   - Configuration tables (if user-configurable)
   - TVFs (for parameterized queries)
   - Metric Views (for self-service analytics)
   - Dashboards (for visualization)
   - Alerts (for proactive monitoring)
   - ML Models (for predictions/forecasting)

3. **Update ALL Relevant Addendums**
   - A single use case often spans multiple addendums
   - Ensure consistency across artifacts
   - Update summary tables

4. **Add Cross-References**
   - Link related artifacts
   - Document dependencies
   - Update main phase1-use-cases.md

### Example: Commit Tracking Use Case

**User Requirement:** "Track actual spend vs Databricks commit amount with forecast"

**Artifacts Created:**

| Addendum | Artifact | Purpose |
|----------|----------|---------|
| Gold Schema | `commit_configurations` table | Store commit amounts |
| 1.2 TVFs | `get_commit_vs_actual` | Query commit status |
| 1.2 TVFs | `get_commit_forecast` | Query ML forecast |
| 1.3 Metric Views | `commit_tracking_metrics` | Self-service analytics |
| 1.5 Dashboards | Commit Tracking Dashboard | Visualization |
| 1.7 Alerts | COST-009/010/011 | Proactive monitoring |
| 1.1 ML Models | Budget Forecaster enhancement | Prediction capability |
| 1.4 Monitoring | Budget variance metrics | Drift detection |

---

## SQL Query Standards

### Gold Layer Reference Pattern

**ALWAYS use Gold layer tables, NEVER system tables directly.**

```sql
-- ‚ùå WRONG: Direct system table reference
FROM system.billing.usage

-- ‚úÖ CORRECT: Gold layer reference with variables
FROM ${catalog}.${gold_schema}.fact_usage
```

### Standard Variable References

```sql
-- Catalog and schema (from parameters)
${catalog}.${gold_schema}.table_name

-- Date parameters (STRING type for Genie compatibility)
WHERE usage_date BETWEEN CAST(start_date AS DATE) AND CAST(end_date AS DATE)

-- SCD Type 2 dimension joins
LEFT JOIN dim_workspace w 
    ON f.workspace_id = w.workspace_id 
    AND w.is_current = TRUE
```

### Tag Query Patterns

For systems with custom tags (e.g., billing):

```sql
-- Tag existence check
WHERE custom_tags IS NOT NULL AND cardinality(custom_tags) > 0

-- Tag value extraction
custom_tags['team'] AS team_tag
COALESCE(custom_tags['cost_center'], 'Unassigned') AS cost_center

-- Tag coverage calculation
SUM(CASE WHEN cardinality(custom_tags) > 0 THEN cost ELSE 0 END) / 
    NULLIF(SUM(cost), 0) * 100 AS tag_coverage_pct
```

---

## Artifact Count Standards

### Minimum Artifacts Per Domain

| Artifact Type | Per Domain | Total (5 domains) |
|---------------|------------|-------------------|
| TVFs | 4-8 | 20-40 |
| Metric Views | 1-2 | 5-10 |
| Dashboard Pages | 2-4 | 10-20 |
| Alerts | 4-8 | 20-40 |
| ML Models | 3-5 | 15-25 |
| Lakehouse Monitors | 1-2 | 5-10 |
| Genie Spaces | 1-2 | 5-10 |

### Artifact Naming Conventions

| Artifact | Pattern | Example |
|----------|---------|---------|
| TVF | `get_<domain>_<metric>` | `get_cost_by_tag` |
| Metric View | `<domain>_analytics_metrics` | `cost_analytics_metrics` |
| Dashboard | `<Domain> <Purpose> Dashboard` | `Cost Attribution Dashboard` |
| Alert | `<DOMAIN>-NNN` | `COST-001` |
| ML Model | `<Purpose> <Type>` | `Budget Forecaster` |
| Monitor | `<table> Monitor` | `Cost Data Quality Monitor` |
| Genie Space | `<Domain> <Purpose>` | `Cost Intelligence` |
|| AI Agent | `<Domain> Agent` | `Cost Agent` |

### Agent Tool Discovery Pattern

Agents discover tools via Genie Space data assets:

```
AGENT: "What are the top cost drivers?"
         ‚îÇ
         ‚ñº
GENIE SPACE: Routes based on question type
‚îú‚îÄ‚îÄ Aggregations ‚Üí Metric Views (cost_analytics)
‚îú‚îÄ‚îÄ Rankings ‚Üí TVFs (get_top_cost_contributors)
‚îú‚îÄ‚îÄ Anomalies ‚Üí ML Tables (cost_anomaly_predictions)
‚îî‚îÄ‚îÄ Trends ‚Üí Monitors (fact_usage_profile_metrics)
         ‚îÇ
         ‚ñº
AGENT: Receives results, synthesizes response
```

---

## Documentation Quality Standards

### LLM-Friendly Comments

All artifacts must have comments that help LLMs (Genie, AI/BI) understand:
- What the artifact does
- When to use it
- Example questions it answers

```sql
COMMENT 'LLM: Returns top N cost contributors by workspace and SKU for a date range.
Use this for cost optimization, chargeback analysis, and identifying spending hotspots.
Parameters: start_date, end_date (YYYY-MM-DD format), optional top_n (default 10).
Example questions: "What are the top 10 cost drivers?" or "Which workspace spent most?"'
```

### Summary Tables

Every addendum must include:
1. **Overview table** - All artifacts with agent domain, dependencies, status
2. **By-domain sections** - Artifacts grouped by agent domain
3. **Count summary** - Total artifacts by type and domain
4. **Success criteria** - Measurable targets

---

## Plan Maintenance

### When to Update Plans

1. **New use case identified** - Add to relevant addendums
2. **Reference material provided** - Enrich with patterns
3. **Implementation starts** - Update status to "In Progress"
4. **Implementation completes** - Update status to "Complete"
5. **Requirements change** - Update affected artifacts

### Version Control

- Plans are documentation, not code
- Track major changes in commit messages
- Reference issues/PRs when available

---

## Validation Checklist

Before finalizing any plan document:

### Structure
- [ ] Follows standard template
- [ ] Has Overview with Status, Dependencies, Effort
- [ ] Organized by Agent Domain
- [ ] Includes code examples
- [ ] Has Success Criteria table
- [ ] Has References section

### Content Quality
- [ ] All queries use Gold layer tables (not system tables)
- [ ] All artifacts tagged with Agent Domain
- [ ] LLM-friendly comments on all artifacts
- [ ] Examples use `${catalog}.${gold_schema}` variables
- [ ] Summary tables are accurate and complete

### Cross-References
- [ ] Main phase document links to addendums
- [ ] Addendums link back to main phase
- [ ] Related artifacts cross-reference each other
- [ ] Dependencies are documented

### Completeness
- [ ] All 5 agent domains covered
- [ ] Minimum artifact counts met
- [ ] User requirements addressed
- [ ] Reference patterns incorporated

---

## Common Mistakes to Avoid

### ‚ùå DON'T: Mix system tables and Gold tables

```sql
-- BAD: Direct system table
FROM system.billing.usage u
JOIN ${catalog}.${gold_schema}.dim_workspace w ...
```

### ‚ùå DON'T: Forget Agent Domain classification

```markdown
## get_slow_queries (BAD - no domain)

## ‚ö° Performance Agent: get_slow_queries (GOOD)
```

### ‚ùå DON'T: Create artifacts without cross-addendum updates

When adding a TVF, also consider:
- Does it need a Metric View counterpart?
- Should there be an Alert?
- Is it Dashboard-worthy?

### ‚ùå DON'T: Use DATE parameters in TVFs (Genie incompatible)

```sql
-- BAD
start_date DATE

-- GOOD
start_date STRING COMMENT 'Format: YYYY-MM-DD'
```

---

## References

### Official Documentation
- [Databricks System Tables](https://docs.databricks.com/administration-guide/system-tables/)
- [Databricks SQL Alerts](https://docs.databricks.com/sql/user/alerts/)
- [Lakehouse Monitoring](https://docs.databricks.com/lakehouse-monitoring/)
- [Metric Views](https://docs.databricks.com/metric-views/)
- [Table-Valued Functions](https://docs.databricks.com/sql/language-manual/sql-ref-syntax-ddl-create-sql-function.html)

### Related Cursor Rules
- [15-databricks-table-valued-functions.mdc](mdc:.cursor/rules/semantic-layer/15-databricks-table-valued-functions.mdc)
- [14-metric-views-patterns.mdc](mdc:.cursor/rules/semantic-layer/14-metric-views-patterns.mdc)
- [17-lakehouse-monitoring-comprehensive.mdc](mdc:.cursor/rules/monitoring/17-lakehouse-monitoring-comprehensive.mdc)
- [18-databricks-aibi-dashboards.mdc](mdc:.cursor/rules/monitoring/18-databricks-aibi-dashboards.mdc)
- [16-genie-space-patterns.mdc](mdc:.cursor/rules/semantic-layer/16-genie-space-patterns.mdc) - **Genie Space setup for agents**

### Agent Framework Documentation
- [Phase 4 - Agent Framework](../plans/phase4-agent-framework.md) - Multi-agent architecture
- [Genie Spaces Deployment Guide](../docs/deployment/GENIE_SPACES_DEPLOYMENT_GUIDE.md) - Agent integration guide

### Project Examples
- [plans/README.md](../plans/README.md) - Index of all plans
- [plans/phase1-use-cases.md](../plans/phase1-use-cases.md) - Master Phase 1 document
- [plans/phase1-addendum-1.7-alerting-framework.md](../plans/phase1-addendum-1.7-alerting-framework.md) - Complete alerting example

---

## Rule Improvement History

**Created:** December 2025  
**Trigger:** Comprehensive plan creation for Databricks Health Monitor project  
**Updated:** December 2025 - Restructured phases to start from Use Cases (Bronze/Silver/Gold as prerequisites)  
**Updated:** December 30, 2025 - Added Agent Layer Architecture pattern (Agents ‚Üí Genie Spaces ‚Üí Data Assets)

**Patterns Documented:** 
- 3-phase project structure (Use Cases ‚Üí Agents ‚Üí Frontend)
- Prerequisites section for completed data layers
- Agent domain framework (5 domains)
- 7 Phase 1 addendums
- 100+ artifacts planned
- Dashboard pattern extraction methodology
- User requirement integration process
- **NEW:** Agent Layer Architecture (Agents use Genie Spaces as query interface)
- **NEW:** Genie Space ‚Üí Agent mapping (1:1 correspondence)
- **NEW:** Multi-agent workflow coordination via Orchestrator
- **NEW:** Three-level testing strategy (Genie ‚Üí Agent ‚Üí Multi-Agent)
- **NEW:** Deployment order requirements (Genie Spaces before Agents)

**Key Learnings:**
1. Agent Domain framework provides consistent organization across all artifacts
2. Gold layer references (not system tables) ensure consistency
3. User requirements often span multiple addendums - update all
4. Dashboard JSON files are rich sources of SQL patterns
5. LLM-friendly comments are critical for Genie/AI/BI integration
6. Summary tables help maintain accuracy across large plans
7. Planning starts after data layers are complete - focus on consumption artifacts
8. **NEW:** Agents should NOT write SQL directly - use Genie Spaces as abstraction
9. **NEW:** Genie Spaces provide natural language understanding that agents leverage
10. **NEW:** Each specialized agent has a dedicated Genie Space (1:1 mapping)
11. **NEW:** Orchestrator agent uses Unified Genie Space for intent classification
12. **NEW:** Genie Spaces must be deployed BEFORE agents can be developed
13. **NEW:** Multi-agent workflows require correlation and synthesis in Orchestrator
14. **NEW:** Three-level testing ensures each layer works before next is built
15. **NEW:** General Instructions in Genie Spaces become agent system prompts
