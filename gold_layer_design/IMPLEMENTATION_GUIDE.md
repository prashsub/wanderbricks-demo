# Wanderbricks Gold Layer - Implementation Guide

## üéâ Implementation Complete!

The Gold layer has been fully implemented using the YAML-driven approach. All scripts, jobs, and configurations are ready for deployment.

---

## üì¶ What Was Created

### 1. Python Implementation Scripts

| File | Purpose | Key Features |
|------|---------|--------------|
| `src/wanderbricks_gold/setup_tables.py` | Generic YAML-driven table creation | ‚Ä¢ Reads YAML schemas<br>‚Ä¢ Generates DDL dynamically<br>‚Ä¢ Applies PK constraints<br>‚Ä¢ Creates all tables from all domains |
| `src/wanderbricks_gold/add_fk_constraints.py` | FK constraint application | ‚Ä¢ Applied AFTER PKs exist<br>‚Ä¢ Reads FK definitions from YAML<br>‚Ä¢ Handles all domains |
| `src/wanderbricks_gold/merge_gold_tables.py` | Delta MERGE from Silver to Gold | ‚Ä¢ Deduplication patterns<br>‚Ä¢ SCD Type 1 & 2 support<br>‚Ä¢ Grain validation<br>‚Ä¢ Schema-aware column mapping |

### 2. Asset Bundle Job Configurations

| File | Purpose | Tasks |
|------|---------|-------|
| `resources/gold/gold_setup_job.yml` | One-time table setup | 1. setup_all_tables<br>2. add_fk_constraints |
| `resources/gold/gold_merge_job.yml` | Periodic MERGE operations | 1. merge_gold_tables |

### 3. Configuration Updates

| File | Change | Purpose |
|------|--------|---------|
| `databricks.yml` | Added `sync` section | Syncs YAML schemas to workspace |
| `databricks.yml` | Added `resources/gold/*.yml` | Includes Gold job definitions |

---

## üöÄ Deployment Steps

### Step 1: Validate Bundle (2 min)

```bash
# Validate configuration
databricks bundle validate

# Expected output:
# ‚úì Configuration is valid
```

### Step 2: Deploy Bundle (3 min)

```bash
# Deploy all resources to dev
databricks bundle deploy -t dev

# Expected output:
# ‚úì Uploaded src/wanderbricks_gold/setup_tables.py
# ‚úì Uploaded src/wanderbricks_gold/add_fk_constraints.py
# ‚úì Uploaded src/wanderbricks_gold/merge_gold_tables.py
# ‚úì Uploaded gold_layer_design/yaml/**/*.yaml
# ‚úì Created job: [dev] Wanderbricks Gold Layer - Setup
# ‚úì Created job: [dev] Wanderbricks Gold Layer - MERGE Updates
```

### Step 3: Create Gold Tables (10-15 min)

```bash
# Run the setup job to create all tables
databricks bundle run gold_setup_job -t dev

# This will:
# 1. Create catalog and schema (wanderbricks_gold)
# 2. Read YAML files from all domains (identity, property, geography, time, booking, engagement)
# 3. Create 8 tables:
#    - dim_user
#    - dim_host
#    - dim_property
#    - dim_destination
#    - dim_date
#    - fact_booking_detail
#    - fact_booking_daily
#    - fact_property_engagement
# 4. Add PRIMARY KEY constraints
# 5. Add FOREIGN KEY constraints

# Expected output:
# ‚úì Created 8 Gold layer tables successfully!
```

### Step 4: Populate Gold Tables (15-20 min)

```bash
# Run the merge job to populate from Silver
databricks bundle run gold_merge_job -t dev

# This will:
# Phase 1: Generate date dimension (2020-2030)
# Phase 2: Merge Type 1 dimensions (dim_destination)
# Phase 3: Merge Type 2 dimensions (dim_user, dim_host, dim_property)
# Phase 4: Merge fact tables (fact_booking_detail, fact_booking_daily, fact_property_engagement)

# Expected output:
# ‚úì Gold layer MERGE completed successfully!
# 
# Table Summary:
#   - dim_user: 1,234 records
#   - dim_host: 567 records
#   - dim_property: 3,456 records
#   - dim_destination: 89 records
#   - dim_date: 4,018 records
#   - fact_booking_detail: 12,345 records
#   - fact_booking_daily: 5,678 records
#   - fact_property_engagement: 8,901 records
```

---

## ‚úÖ Validation Queries

### 1. Verify Tables Created

```sql
USE CATALOG prashanth_subrahmanyam_catalog;
SHOW TABLES IN wanderbricks_gold;

-- Expected: 8 tables (5 dimensions, 3 facts)
```

### 2. Verify PRIMARY KEY Constraints

```sql
-- Check dim_user constraint
SHOW CREATE TABLE prashanth_subrahmanyam_catalog.wanderbricks_gold.dim_user;

-- Expected: PRIMARY KEY (user_key)
```

### 3. Verify FOREIGN KEY Constraints

```sql
-- Check fact_booking_detail FKs
DESCRIBE TABLE EXTENDED prashanth_subrahmanyam_catalog.wanderbricks_gold.fact_booking_detail;

-- Expected: FK constraints to dim_user, dim_host, dim_property, dim_destination
```

### 4. Verify Grain (No Duplicates)

```sql
-- Fact: fact_booking_detail (should be 0)
SELECT 
  booking_id, COUNT(*) as dup_count
FROM prashanth_subrahmanyam_catalog.wanderbricks_gold.fact_booking_detail
GROUP BY booking_id
HAVING COUNT(*) > 1;

-- Fact: fact_booking_daily (should be 0)
SELECT 
  property_id, check_in_date, COUNT(*) as dup_count
FROM prashanth_subrahmanyam_catalog.wanderbricks_gold.fact_booking_daily
GROUP BY property_id, check_in_date
HAVING COUNT(*) > 1;

-- Dimension: dim_user current versions (should be 0)
SELECT 
  user_id, COUNT(*) as current_versions
FROM prashanth_subrahmanyam_catalog.wanderbricks_gold.dim_user
WHERE is_current = true
GROUP BY user_id
HAVING COUNT(*) > 1;
```

### 5. Verify FK Integrity (No Orphans)

```sql
-- Check fact_booking_detail ‚Üí dim_user
SELECT COUNT(*) as orphaned_bookings
FROM prashanth_subrahmanyam_catalog.wanderbricks_gold.fact_booking_detail f
LEFT JOIN prashanth_subrahmanyam_catalog.wanderbricks_gold.dim_user d
  ON f.user_id = d.user_id AND d.is_current = true
WHERE d.user_id IS NULL;

-- Expected: 0 orphaned records
```

### 6. Verify Record Counts

```sql
-- Compare Silver vs Gold counts (should be similar)
SELECT 
  'silver_bookings' as source,
  COUNT(*) as record_count
FROM prashanth_subrahmanyam_catalog.wanderbricks_silver.silver_bookings

UNION ALL

SELECT 
  'gold_fact_booking_detail' as source,
  COUNT(*) as record_count
FROM prashanth_subrahmanyam_catalog.wanderbricks_gold.fact_booking_detail;
```

---

## üîß Implementation Patterns Applied

### 1. YAML-Driven Table Creation
‚úÖ **Pattern:** Generic script reads YAML, generates DDL dynamically  
‚úÖ **Benefit:** Schema changes = YAML edits only (no Python changes)  
‚úÖ **Rule:** [25-yaml-driven-gold-setup.mdc](mdc:.cursor/rules/gold/25-yaml-driven-gold-setup.mdc)

### 2. FK Constraints Applied After PKs
‚úÖ **Pattern:** ALTER TABLE ADD CONSTRAINT after all tables exist  
‚úÖ **Benefit:** Prevents "table does not have a primary key" errors  
‚úÖ **Rule:** [05-unity-catalog-constraints.mdc](mdc:.cursor/rules/common/05-unity-catalog-constraints.mdc)

### 3. Schema-Aware Column Mapping
‚úÖ **Pattern:** Explicit `.withColumn()` for renames (e.g., `company_rcn` ‚Üí `company_retail_control_number`)  
‚úÖ **Benefit:** Prevents "column not found" errors  
‚úÖ **Rule:** [10-gold-layer-merge-patterns.mdc](mdc:.cursor/rules/gold/10-gold-layer-merge-patterns.mdc)

### 4. Deduplication Before MERGE
‚úÖ **Pattern:** `orderBy().dropDuplicates()` on latest timestamp  
‚úÖ **Benefit:** Prevents DELTA_MULTIPLE_SOURCE_ROW_MATCHING_TARGET_ROW_IN_MERGE error  
‚úÖ **Rule:** [11-gold-delta-merge-deduplication.mdc](mdc:.cursor/rules/gold/11-gold-delta-merge-deduplication.mdc)

### 5. Grain Validation
‚úÖ **Pattern:** Validate distinct grain count = total row count  
‚úÖ **Benefit:** Catches aggregation errors before MERGE  
‚úÖ **Rule:** [24-fact-table-grain-validation.mdc](mdc:.cursor/rules/gold/24-fact-table-grain-validation.mdc)

### 6. Schema Validation
‚úÖ **Pattern:** Validate DataFrame columns match DDL before MERGE  
‚úÖ **Benefit:** Prevents schema mismatch errors  
‚úÖ **Rule:** [23-gold-layer-schema-validation.mdc](mdc:.cursor/rules/gold/23-gold-layer-schema-validation.mdc)

---

## üìä Gold Layer Architecture

### Dimensions (5 tables)

| Table | Type | Business Key | Surrogate Key | Grain |
|-------|------|--------------|---------------|-------|
| `dim_user` | SCD Type 2 | user_id | user_key | One row per user version |
| `dim_host` | SCD Type 2 | host_id | host_key | One row per host version |
| `dim_property` | SCD Type 2 | property_id | property_key | One row per property version |
| `dim_destination` | SCD Type 1 | destination_id | N/A | One row per destination |
| `dim_date` | Generated | date | N/A | One row per date (2020-2030) |

### Facts (3 tables)

| Table | Grain | Type | Source |
|-------|-------|------|--------|
| `fact_booking_detail` | One row per booking | Transaction | silver_bookings + silver_payments |
| `fact_booking_daily` | One row per property per check-in date | Aggregated | silver_bookings |
| `fact_property_engagement` | One row per property per engagement date | Aggregated | silver_page_views + silver_clickstream |

---

## üîÑ Data Flow

```
Silver Layer (Validated)
    ‚îÇ
    ‚îú‚îÄ> dim_user (SCD Type 2)
    ‚îÇ   ‚îî‚îÄ> silver_user_dim
    ‚îÇ
    ‚îú‚îÄ> dim_host (SCD Type 2)
    ‚îÇ   ‚îî‚îÄ> silver_host_dim
    ‚îÇ
    ‚îú‚îÄ> dim_property (SCD Type 2)
    ‚îÇ   ‚îî‚îÄ> silver_property_dim
    ‚îÇ
    ‚îú‚îÄ> dim_destination (SCD Type 1)
    ‚îÇ   ‚îî‚îÄ> silver_destination_dim
    ‚îÇ
    ‚îú‚îÄ> dim_date (Generated)
    ‚îÇ   ‚îî‚îÄ> SQL SEQUENCE (2020-2030)
    ‚îÇ
    ‚îú‚îÄ> fact_booking_detail (Transaction)
    ‚îÇ   ‚îî‚îÄ> silver_bookings + silver_payments
    ‚îÇ
    ‚îú‚îÄ> fact_booking_daily (Aggregated)
    ‚îÇ   ‚îî‚îÄ> silver_bookings
    ‚îÇ
    ‚îî‚îÄ> fact_property_engagement (Aggregated)
        ‚îî‚îÄ> silver_page_views + silver_clickstream
```

---

## üêõ Troubleshooting

### Issue 1: YAML Files Not Found

**Error:**
```
FileNotFoundError: YAML directory not found
```

**Solution:**
Check that YAMLs are synced in `databricks.yml`:
```yaml
sync:
  include:
    - gold_layer_design/yaml/**/*.yaml
```

Then redeploy:
```bash
databricks bundle deploy -t dev
```

---

### Issue 2: PyYAML Not Available

**Error:**
```
ModuleNotFoundError: No module named 'yaml'
```

**Solution:**
Check that dependency is in job environment:
```yaml
environments:
  - environment_key: default
    spec:
      dependencies:
        - "pyyaml>=6.0"
```

This is already configured in `gold_setup_job.yml`.

---

### Issue 3: Duplicate Key MERGE Error

**Error:**
```
[DELTA_MULTIPLE_SOURCE_ROW_MATCHING_TARGET_ROW_IN_MERGE] Cannot perform MERGE as multiple source rows matched...
```

**Solution:**
Deduplication is already implemented in merge scripts:
```python
silver_df = (
    silver_raw
    .orderBy(col("processed_timestamp").desc())
    .dropDuplicates(["business_key"])
)
```

If error persists, check Silver source for actual duplicates.

---

### Issue 4: FK Constraint Error

**Error:**
```
[DELTA_FK_CONSTRAINT_ERROR] The table does not have a primary key on column(s) 'user_id'
```

**Solution:**
FK constraints must be applied AFTER all PKs exist. This is handled by the 2-task setup job:
1. `setup_all_tables` - Creates tables + PKs
2. `add_fk_constraints` - Applies FKs

Ensure both tasks run successfully.

---

### Issue 5: Column Not Found

**Error:**
```
[UNRESOLVED_COLUMN] A column with name 'company_retail_control_number' cannot be resolved
```

**Solution:**
Check column mapping in merge script. Example:
```python
# Add explicit column mapping
.withColumn("company_retail_control_number", col("company_rcn"))
```

This is already implemented in `merge_gold_tables.py`.

---

## üìà Performance Considerations

### Table Properties (Already Applied)

All Gold tables have these performance properties:

```python
STANDARD_PROPERTIES = {
    "delta.enableChangeDataFeed": "true",
    "delta.enableRowTracking": "true",
    "delta.enableDeletionVectors": "true",
    "delta.autoOptimize.autoCompact": "true",
    "delta.autoOptimize.optimizeWrite": "true",
    "layer": "gold",
}
```

### Clustering (Automatic)

All tables use `CLUSTER BY AUTO` - Delta automatically selects optimal clustering columns.

### Predictive Optimization

Enabled at schema level:
```sql
ALTER SCHEMA wanderbricks_gold
SET TBLPROPERTIES (
    'databricks.pipelines.predictiveOptimizations.enabled' = 'true'
);
```

---

## üéØ Next Steps

After Gold layer implementation:

1. **Metric Views** - Create semantic layer for Genie  
   üìÑ Use [04-metric-views-prompt.md](../context/prompts/04-metric-views-prompt.md)

2. **Table-Valued Functions** - Create parameterized queries for Genie  
   üìÑ Use [15-databricks-table-valued-functions.mdc](mdc:.cursor/rules/semantic-layer/15-databricks-table-valued-functions.mdc)

3. **Lakehouse Monitoring** - Monitor Gold table quality and drift  
   üìÑ Use [17-lakehouse-monitoring-comprehensive.mdc](mdc:.cursor/rules/monitoring/17-lakehouse-monitoring-comprehensive.mdc)

4. **AI/BI Dashboards** - Create business dashboards  
   üìÑ Use [18-databricks-aibi-dashboards.mdc](mdc:.cursor/rules/monitoring/18-databricks-aibi-dashboards.mdc)

5. **Genie Space** - Deploy natural language query interface  
   üìÑ Use [16-genie-space-patterns.mdc](mdc:.cursor/rules/semantic-layer/16-genie-space-patterns.mdc)

---

## üìö Reference Documentation

### Gold Layer Rules
- [25-yaml-driven-gold-setup.mdc](mdc:.cursor/rules/gold/25-yaml-driven-gold-setup.mdc) - YAML patterns
- [23-gold-layer-schema-validation.mdc](mdc:.cursor/rules/gold/23-gold-layer-schema-validation.mdc) - Schema validation
- [24-fact-table-grain-validation.mdc](mdc:.cursor/rules/gold/24-fact-table-grain-validation.mdc) - Grain validation
- [11-gold-delta-merge-deduplication.mdc](mdc:.cursor/rules/gold/11-gold-delta-merge-deduplication.mdc) - Deduplication
- [10-gold-layer-merge-patterns.mdc](mdc:.cursor/rules/gold/10-gold-layer-merge-patterns.mdc) - MERGE patterns
- [12-gold-layer-documentation.mdc](mdc:.cursor/rules/gold/12-gold-layer-documentation.mdc) - Documentation standards

### Official Databricks Documentation
- [Delta MERGE](https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge)
- [Unity Catalog Constraints](https://docs.databricks.com/data-governance/unity-catalog/constraints.html)
- [Databricks Asset Bundles](https://docs.databricks.com/dev-tools/bundles/)
- [Automatic Clustering](https://docs.databricks.com/delta/clustering.html)

---

## üìù Summary

**‚úÖ Implementation Status:** Complete

**Created Files:**
- 3 Python scripts (setup, FK constraints, merge)
- 2 Asset Bundle jobs (setup, merge)
- 1 Configuration update (databricks.yml)

**Tables Created:**
- 5 Dimensions (1 Type 1, 3 Type 2, 1 Generated)
- 3 Facts (1 Transaction, 2 Aggregated)

**Patterns Applied:**
- YAML-driven table creation
- FK constraints after PKs
- Deduplication before MERGE
- Grain validation
- Schema validation
- Column mapping

**Deployment Time:**
- Validation: 2 min
- Deploy: 3 min
- Setup tables: 10-15 min
- Populate: 15-20 min
- **Total: ~30-40 min**

**Next Action:** Deploy and validate with steps above! üöÄ

